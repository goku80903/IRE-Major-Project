{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.idle":"2021-10-26T12:28:35.469067Z","shell.execute_reply":"2021-10-26T12:28:35.468057Z","shell.execute_reply.started":"2021-10-26T12:28:09.33394Z"},"trusted":true},"outputs":[],"source":["# !rm -rf /content/sample_data\n","# !unzip \"/kaggle/input/webnlg/webnlg-dataset-master-release_v3.0.zip\"\n","!mkdir /kaggle/working/data\n","!cp -r /kaggle/input/webnlg3/webnlg-dataset-master-release_v3.0/release_v3.0/en/* /kaggle/working/data\n","!pip install sentencepiece\n","!pip install transformers\n","!pip install deep_translator"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-10-26T12:28:38.301907Z","iopub.status.busy":"2021-10-26T12:28:38.301153Z","iopub.status.idle":"2021-10-26T12:28:40.213156Z","shell.execute_reply":"2021-10-26T12:28:40.212184Z","shell.execute_reply.started":"2021-10-26T12:28:38.301865Z"},"trusted":true},"outputs":[],"source":["import os\n","from xml.etree import ElementTree as ET\n","from collections import Counter\n","from functools import reduce\n","import operator\n","from torch.utils.data import IterableDataset,DataLoader\n","from tqdm import tqdm\n","import random\n","import re\n","import numpy as np\n","import random\n","from deep_translator import GoogleTranslator\n","import pandas as pd"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-10-26T12:28:44.318539Z","iopub.status.busy":"2021-10-26T12:28:44.318071Z","iopub.status.idle":"2021-10-26T12:28:44.325446Z","shell.execute_reply":"2021-10-26T12:28:44.32457Z","shell.execute_reply.started":"2021-10-26T12:28:44.318495Z"},"trusted":true},"outputs":[],"source":["def get_triple_and_text(filepath='/kaggle/working/data/en/train/7triples/Astronaut.xml'):\n","    '''\n","    Function that reads an xml file and generates triple text pairs.\n","    Arguments\n","      -- filepath:str\n","         path to the xml file\n","    Returns\n","    A generator that yields a tuple of tripleset and corresponding reference texts.\n","    '''\n","    triples, texts = [], []\n","    #parsing the xml file \n","    for _, elem in ET.iterparse(filepath, events=(\"end\",)):      \n","        if elem.tag.endswith(\"entry\"):\n","            # At the end of every entry tag return triple set and texts\n","            # collected so far and clear accumulators\n","            yield triples, texts\n","            triples, texts = [], []\n","            triple, text = None, None\n","        elif elem.tag.endswith(\"lex\"):\n","            # Each tag ending with lex contains reference texts for that entry\n","            text = elem.text\n","            texts.append(text)\n","        elif elem.tag.endswith(\"mtriple\"):\n","            # Each tag ending with mtriple contains one triple for that entry\n","            triple = elem.text\n","            triples.append(triple)\n","        else:\n","            #Ignore all other tags\n","            pass\n","        elem.clear()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-10-26T12:28:56.782692Z","iopub.status.busy":"2021-10-26T12:28:56.782291Z","iopub.status.idle":"2021-10-26T12:28:57.557311Z","shell.execute_reply":"2021-10-26T12:28:57.556492Z","shell.execute_reply.started":"2021-10-26T12:28:56.782655Z"},"trusted":true},"outputs":[],"source":["class dataset(IterableDataset):\n","    '''\n","    Dataset class inherited from pytorch iterabledataset.\n","    It works with generator instead of providing completed data set. \n","    '''\n","    def __init__(self,sampler):\n","        '''\n","         Arguments\n","         -- sampler: generator object\n","            A generator that yields one sample at a time.\n","        '''\n","        self.sampler = sampler\n","    def __iter__(self):\n","        return self.sampler()\n","\n","def get_data_loader(root,datasplit,batch_size=4):\n","    '''\n","    This Function generates a data loader.\n","    Arguments\n","         -- root: str\n","            Root directory of the dataset\n","         -- datasplit: str\n","            Control which data split to use. \n","            It can take values \"train\",\"dev or \"test\"\n","        -- batch_size: int\n","            Batch of the data loader.\n","    Returns\n","         -- Data Loader object\n","    \n","    '''\n","    def get_data_stream_generator(root,datasplit):\n","        '''\n","        Generates one clean seq2seq sample\n","        Arguments\n","         -- root: str\n","            Root directory of the dataset\n","         -- datasplit: str\n","            Control which data split to use. \n","            It can take values \"train\",\"dev or \"test\"\n","        Returns\n","         -- Generator that yields one sample on each call \n","        '''\n","        # Get all file names containing data\n","        files = [path+'/'+file for path,subdir,files in os.walk(root) if datasplit in path for file in files]\n","        # Use generator get the triples in all files.\n","        triples,texts = list(zip(*[list(zip(*list(get_triple_and_text(i)))) for i in tqdm(files)]))\n","        triples, texts = list(reduce(operator.concat,triples)), list(reduce(operator.concat,texts))\n","\n","    \n","        def linearize(triple):\n","            '''\n","            Converts a set of triples into a sequence.\n","            Arguments\n","                -- triple: list[str]\n","                   List of triples in a RDF\n","            Returns\n","                A string containing information from triples\n","            '''\n","            return 'T '+' T '.join(['<S> '+each.replace('|','<R>',1).replace('|','<O>',1) for each in triple])\n","\n","        def get_sample():\n","            '''\n","            Utility function that shuffles the data.\n","            '''\n","            indexes=list(range(len(triples)))\n","            random.shuffle(indexes)\n","            for l in [(linearize(triples[i]),k) for i in indexes for k in texts[i]]:yield l\n","        return get_sample\n","\n","    sampler = get_data_stream_generator(root,datasplit)\n","    data = dataset(sampler)\n","    loader = DataLoader(data,batch_size=batch_size)\n","    return loader\n","\n","# Get Data Loader for training and validation\n","train_loader = get_data_loader('/kaggle/working/data','train',16)\n","val_loader = get_data_loader('/kaggle/working/data','dev',16)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-10-26T12:29:01.295719Z","iopub.status.busy":"2021-10-26T12:29:01.295101Z","iopub.status.idle":"2021-10-26T12:29:02.066997Z","shell.execute_reply":"2021-10-26T12:29:02.066057Z","shell.execute_reply.started":"2021-10-26T12:29:01.295676Z"},"trusted":true},"outputs":[],"source":["import torch\n","\n","# Clear GPU \n","torch.cuda.empty_cache()\n","try:\n","    import gc\n","    model=None\n","    gc.collect()\n","except:\n","    pass\n","!nvidia-smi"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-10-26T12:29:07.064098Z","iopub.status.busy":"2021-10-26T12:29:07.063128Z","iopub.status.idle":"2021-10-26T12:29:22.089797Z","shell.execute_reply":"2021-10-26T12:29:22.088957Z","shell.execute_reply.started":"2021-10-26T12:29:07.064051Z"},"trusted":true},"outputs":[],"source":["from transformers import T5Tokenizer, T5ForConditionalGeneration\n","import torch\n","from torch import optim\n","\n","# Loading T5Model and tokenizer\n","tokenizer = T5Tokenizer.from_pretrained(\"t5-small\")\n","model = T5ForConditionalGeneration.from_pretrained(\"t5-small\")\n","#Adding Special tokens\n","tokenizer.add_tokens(['<s>', '<R>','<O>'])\n","model.resize_token_embeddings(len(tokenizer))\n","\n","#Preparing model for training\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","model.to(device)\n","optimizer = optim.Adagrad(model.parameters(),lr =1e-3)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-10-26T12:29:22.091558Z","iopub.status.busy":"2021-10-26T12:29:22.091285Z","iopub.status.idle":"2021-10-26T12:29:22.102153Z","shell.execute_reply":"2021-10-26T12:29:22.09998Z","shell.execute_reply.started":"2021-10-26T12:29:22.091521Z"},"trusted":true},"outputs":[],"source":["def validate(model,valloader):\n","    '''\n","    Validation Loop\n","    Aguments\n","        -- model: model object\n","        -- valloader: Validation Data Loader\n","    '''\n","    model.eval()\n","    losses=[]\n","    #Evaluation Loop\n","    for data in valloader:\n","        input_string,target_string = data\n","        encoding = tokenizer(input_string,\n","                          padding='longest',\n","                          max_length=75,\n","                          truncation=True,\n","                          return_tensors=\"pt\")\n","        input_ids, attention_mask = encoding.input_ids, encoding.attention_mask\n","\n","        # encode the targets\n","        target_encoding = tokenizer(target_string,\n","                                    padding='longest',\n","                                    max_length=100,\n","                                    truncation=True)\n","        labels = target_encoding.input_ids\n","        # replace padding token id's of the labels by -100\n","        labels = [\n","                  [(label if label != tokenizer.pad_token_id else -100) for label in labels_example] for labels_example in labels\n","        ]\n","        labels = torch.tensor(labels)\n","\n","        # forward pass\n","        input_ids = input_ids.to(device)\n","        attention_mask = attention_mask.to(device)\n","        labels = labels.to(device)\n","        loss = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels).loss\n","        losses.append(loss.tolist())\n","    print('Evaluation loss ',np.array(losses).mean())"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-10-26T12:30:15.106394Z","iopub.status.busy":"2021-10-26T12:30:15.105842Z","iopub.status.idle":"2021-10-26T16:00:44.01338Z","shell.execute_reply":"2021-10-26T16:00:44.012626Z","shell.execute_reply.started":"2021-10-26T12:30:15.106354Z"},"trusted":true},"outputs":[],"source":["for epoch in tqdm(range(30)):\n","    losses=[]\n","    with torch.no_grad():\n","        validate(model,val_loader)\n","    for batch,data in enumerate(train_loader):\n","        input_string,target_string = data\n","        optimizer.zero_grad()\n","        encoding = tokenizer(input_string,\n","                          padding='longest',\n","                          max_length=75,\n","                          truncation=True,\n","                          return_tensors=\"pt\")\n","        input_ids, attention_mask = encoding.input_ids, encoding.attention_mask\n","\n","        # encode the targets\n","        target_encoding = tokenizer(target_string,\n","                                    padding='longest',\n","                                    max_length=100,\n","                                    truncation=True)\n","        labels = target_encoding.input_ids\n","        # replace padding token id's of the labels by -100\n","        # Token -100  is ignored by pytorch when calculating loss\n","        labels = [\n","                  [(label if label != tokenizer.pad_token_id else -100) for label in labels_example] for labels_example in labels\n","        ]\n","        labels = torch.tensor(labels)\n","\n","        # forward pass\n","        input_ids = input_ids.to(device)\n","        attention_mask = attention_mask.to(device)\n","        labels = labels.to(device)\n","        model.train()\n","        loss = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels).loss\n","\n","        # Backward pass\n","        loss.backward()\n","        # Gradient Update\n","        optimizer.step()\n","\n","        losses.append(loss.tolist())\n","        if batch%500==499:\n","            print('Training Loss ',np.array(losses).mean(),' at batch ',batch,end=' | ')\n","            with torch.no_grad():\n","                validate(model,val_loader)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-10-26T16:00:44.015708Z","iopub.status.busy":"2021-10-26T16:00:44.015198Z","iopub.status.idle":"2021-10-26T16:00:44.492295Z","shell.execute_reply":"2021-10-26T16:00:44.491479Z","shell.execute_reply.started":"2021-10-26T16:00:44.015667Z"},"trusted":true},"outputs":[],"source":["#Saving Model and tokenizer\n","model.save_pretrained('kaggle/working/finetuned-t5-30-model')\n","tokenizer.save_pretrained('kaggle/working/finetuned-t5-30-model')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-10-26T16:03:29.361624Z","iopub.status.busy":"2021-10-26T16:03:29.361209Z","iopub.status.idle":"2021-10-26T16:03:29.511694Z","shell.execute_reply":"2021-10-26T16:03:29.510947Z","shell.execute_reply.started":"2021-10-26T16:03:29.361571Z"},"trusted":true},"outputs":[],"source":["def get_ref_targets(root,datasplit):\n","        '''\n","        Function that returns a generator  object that returns one sample at a time\n","        Contains multiple reference texts for one triple set.\n","        Arguments\n","            -- root:str\n","               Root directory of the data set\n","            -- datasplit: str\n","               DataSplit to use\n","        Returns\n","            Data generator object\n","        '''\n","        files = [path+'/'+file for path,subdir,files in os.walk(root) if datasplit in path for file in files]\n","        triples,texts = list(zip(*[list(zip(*list(get_triple_and_text(i)))) for i in tqdm(files)]))\n","        triples, texts = list(reduce(operator.concat,triples)), list(reduce(operator.concat,texts))\n","\n","    \n","        def linearize(x):\n","            '''\n","            Converts a set of triples into a sequence.\n","            Arguments\n","                -- triple: list[str]\n","                   List of triples in a RDF\n","            Returns\n","                A string containing information from triples\n","            '''\n","            return 'T '+' T '.join(['<S> '+each.replace('|','<R>',1).replace('|','<O>',1) for each in x])\n","\n","        def get_sample():\n","            '''Utility function that shuffles data.'''\n","            indexes=list(range(len(triples)))\n","            random.shuffle(indexes)\n","            for l in [(linearize(triples[i]),texts[i]) for i in indexes]:yield l\n","        return get_sample\n","def get_text(inp):\n","    '''\n","    Takes a linearized tripleset as input and generates Natural language text.\n","    Arguments\n","        -- inp: str\n","           Input Sequence\n","    Returns\n","        Model Generated text\n","    '''\n","    with torch.no_grad():\n","        # Tokenize input\n","        test_input_ids = tokenizer(inp, return_tensors='pt').input_ids\n","        # Send the data to gpu\n","        test_input_ids = test_input_ids.to(device)\n","        # call models generate method\n","        test_outputs = model.generate(test_input_ids,max_length=100)\n","        # Convert model output into human readable text\n","        test_outputs = test_outputs.to(torch.device('cpu'))\n","        return tokenizer.decode(test_outputs[0], skip_special_tokens=True)\n","test_streamer = get_ref_targets('/kaggle/working/data','dev')\n"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2021-10-26T16:06:39.877678Z","iopub.status.busy":"2021-10-26T16:06:39.876873Z","iopub.status.idle":"2021-10-26T16:15:37.602972Z","shell.execute_reply":"2021-10-26T16:15:37.602266Z","shell.execute_reply.started":"2021-10-26T16:06:39.877631Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["1667it [08:57,  3.10it/s]\n"]}],"source":["y_pred=[]\n","y_true=[]\n","y_pred_text=[]\n","y_true_text=[]\n","inps =[]\n","#Inference Loop for all data samples\n","for data in tqdm(test_streamer()):\n","    inp,ref = data\n","    inps.append(inp)\n","    y=get_text(inp)\n","    y_pred_text.append(y)\n","    y_true_text.append(ref)\n","    y_pred.append([tokenizer.tokenize(i) for i in [y]])\n","    y_true.append([tokenizer.tokenize(i) for i in ref])\n","\n","    "]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2021-10-26T16:17:59.343922Z","iopub.status.busy":"2021-10-26T16:17:59.343361Z","iopub.status.idle":"2021-10-26T16:17:59.415014Z","shell.execute_reply":"2021-10-26T16:17:59.414284Z","shell.execute_reply.started":"2021-10-26T16:17:59.343882Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>inps</th>\n","      <th>y_pred_text</th>\n","      <th>y_true_text</th>\n","      <th>y_pred</th>\n","      <th>y_true</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>T &lt;S&gt; Alan_Frew &lt;R&gt; associatedBand/associatedM...</td>\n","      <td>Alan Frew is associated with Glass Tiger.</td>\n","      <td>[Alan Frew plays with Glass Tiger., Alan Frew ...</td>\n","      <td>[[▁Alan, ▁Fre, w, ▁is, ▁associated, ▁with, ▁Gl...</td>\n","      <td>[[▁Alan, ▁Fre, w, ▁plays, ▁with, ▁Glass, ▁Tige...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>T &lt;S&gt; Bakewell_pudding &lt;R&gt; region &lt;O&gt; Derbyshi...</td>\n","      <td>Bakewell tart is a variation of Bakewell tart ...</td>\n","      <td>[From the Derbyshire Dales region (in Derbyshi...</td>\n","      <td>[[▁Bake, well, ▁tart, ▁is, ▁, a, ▁variation, ▁...</td>\n","      <td>[[▁From, ▁the, ▁Derby, shire, ▁Da, les, ▁regio...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>T &lt;S&gt; Ardmore_Airport_(New_Zealand) &lt;R&gt; 2ndRun...</td>\n","      <td>The 2nd runway at Ardmore Airport (New Zealand...</td>\n","      <td>[New Zealand's Ardmore Airport's second runway...</td>\n","      <td>[[▁The, ▁2, nd, ▁runway, ▁at, ▁Ard, more, ▁Air...</td>\n","      <td>[[▁New, ▁Zealand, ', s, ▁Ard, more, ▁Airport, ...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>T &lt;S&gt; Canada &lt;R&gt; anthem &lt;O&gt; O_Canada T &lt;S&gt; Can...</td>\n","      <td>The anthem of Canada is O Canada and the leade...</td>\n","      <td>[Aaron Boogaard was born in Canada whose natio...</td>\n","      <td>[[▁The, ▁, ant, hem, ▁of, ▁Canada, ▁is, ▁O, ▁C...</td>\n","      <td>[[▁Aaron, ▁Bo, oga, ard, ▁was, ▁born, ▁in, ▁Ca...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>T &lt;S&gt; Appleton_International_Airport &lt;R&gt; locat...</td>\n","      <td>Appleton International Airport is located in G...</td>\n","      <td>[The city of Appleton is served by Appleton In...</td>\n","      <td>[[▁App, leton, ▁International, ▁Airport, ▁is, ...</td>\n","      <td>[[▁The, ▁city, ▁of, ▁App, leton, ▁is, ▁served,...</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>1662</th>\n","      <td>T &lt;S&gt; Antares_(rocket) &lt;R&gt; manufacturer &lt;O&gt; Yu...</td>\n","      <td>The Antares rocket, which was launched from th...</td>\n","      <td>[The Antares rocket is manufactured at the Yuz...</td>\n","      <td>[[▁The, ▁Ant, are, s, ▁rocket, ,, ▁which, ▁was...</td>\n","      <td>[[▁The, ▁Ant, are, s, ▁rocket, ▁is, ▁manufactu...</td>\n","    </tr>\n","    <tr>\n","      <th>1663</th>\n","      <td>T &lt;S&gt; ACM_Transactions_on_Information_Systems ...</td>\n","      <td>ACM Transactions on Information Systems (abbre...</td>\n","      <td>[ACM Transactions on Information Systems, or A...</td>\n","      <td>[[▁A, CM, ▁Transaction, s, ▁on, ▁Information, ...</td>\n","      <td>[[▁A, CM, ▁Transaction, s, ▁on, ▁Information, ...</td>\n","    </tr>\n","    <tr>\n","      <th>1664</th>\n","      <td>T &lt;S&gt; Angola_International_Airport &lt;R&gt; locatio...</td>\n","      <td>Angola International Airport is located in col...</td>\n","      <td>[Angola International airport is located in Ic...</td>\n","      <td>[[▁An, gol, a, ▁International, ▁Airport, ▁is, ...</td>\n","      <td>[[▁An, gol, a, ▁International, ▁airport, ▁is, ...</td>\n","    </tr>\n","    <tr>\n","      <th>1665</th>\n","      <td>T &lt;S&gt; Ace_Wilder &lt;R&gt; genre &lt;O&gt; Hip_hop_music T...</td>\n","      <td>Ace Wilder is a hip hop musician and his music...</td>\n","      <td>[Ace Wilder is an exponent of hip hop music, a...</td>\n","      <td>[[▁Ace, ▁Wild, er, ▁is, ▁, a, ▁hip, ▁hop, ▁mus...</td>\n","      <td>[[▁Ace, ▁Wild, er, ▁is, ▁an, ▁ex, ponent, ▁of,...</td>\n","    </tr>\n","    <tr>\n","      <th>1666</th>\n","      <td>T &lt;S&gt; Germany &lt;R&gt; capital &lt;O&gt; Berlin T &lt;S&gt; Nep...</td>\n","      <td>The A-Rosa Luna was built by Neptun Werft, the...</td>\n","      <td>[The A-Rosa Luna was built on the Neptun Werft...</td>\n","      <td>[[▁The, ▁A, -, R, o, s, a, ▁Luna, ▁was, ▁built...</td>\n","      <td>[[▁The, ▁A, -, R, o, s, a, ▁Luna, ▁was, ▁built...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>1667 rows × 5 columns</p>\n","</div>"],"text/plain":["                                                   inps  \\\n","0     T <S> Alan_Frew <R> associatedBand/associatedM...   \n","1     T <S> Bakewell_pudding <R> region <O> Derbyshi...   \n","2     T <S> Ardmore_Airport_(New_Zealand) <R> 2ndRun...   \n","3     T <S> Canada <R> anthem <O> O_Canada T <S> Can...   \n","4     T <S> Appleton_International_Airport <R> locat...   \n","...                                                 ...   \n","1662  T <S> Antares_(rocket) <R> manufacturer <O> Yu...   \n","1663  T <S> ACM_Transactions_on_Information_Systems ...   \n","1664  T <S> Angola_International_Airport <R> locatio...   \n","1665  T <S> Ace_Wilder <R> genre <O> Hip_hop_music T...   \n","1666  T <S> Germany <R> capital <O> Berlin T <S> Nep...   \n","\n","                                            y_pred_text  \\\n","0             Alan Frew is associated with Glass Tiger.   \n","1     Bakewell tart is a variation of Bakewell tart ...   \n","2     The 2nd runway at Ardmore Airport (New Zealand...   \n","3     The anthem of Canada is O Canada and the leade...   \n","4     Appleton International Airport is located in G...   \n","...                                                 ...   \n","1662  The Antares rocket, which was launched from th...   \n","1663  ACM Transactions on Information Systems (abbre...   \n","1664  Angola International Airport is located in col...   \n","1665  Ace Wilder is a hip hop musician and his music...   \n","1666  The A-Rosa Luna was built by Neptun Werft, the...   \n","\n","                                            y_true_text  \\\n","0     [Alan Frew plays with Glass Tiger., Alan Frew ...   \n","1     [From the Derbyshire Dales region (in Derbyshi...   \n","2     [New Zealand's Ardmore Airport's second runway...   \n","3     [Aaron Boogaard was born in Canada whose natio...   \n","4     [The city of Appleton is served by Appleton In...   \n","...                                                 ...   \n","1662  [The Antares rocket is manufactured at the Yuz...   \n","1663  [ACM Transactions on Information Systems, or A...   \n","1664  [Angola International airport is located in Ic...   \n","1665  [Ace Wilder is an exponent of hip hop music, a...   \n","1666  [The A-Rosa Luna was built on the Neptun Werft...   \n","\n","                                                 y_pred  \\\n","0     [[▁Alan, ▁Fre, w, ▁is, ▁associated, ▁with, ▁Gl...   \n","1     [[▁Bake, well, ▁tart, ▁is, ▁, a, ▁variation, ▁...   \n","2     [[▁The, ▁2, nd, ▁runway, ▁at, ▁Ard, more, ▁Air...   \n","3     [[▁The, ▁, ant, hem, ▁of, ▁Canada, ▁is, ▁O, ▁C...   \n","4     [[▁App, leton, ▁International, ▁Airport, ▁is, ...   \n","...                                                 ...   \n","1662  [[▁The, ▁Ant, are, s, ▁rocket, ,, ▁which, ▁was...   \n","1663  [[▁A, CM, ▁Transaction, s, ▁on, ▁Information, ...   \n","1664  [[▁An, gol, a, ▁International, ▁Airport, ▁is, ...   \n","1665  [[▁Ace, ▁Wild, er, ▁is, ▁, a, ▁hip, ▁hop, ▁mus...   \n","1666  [[▁The, ▁A, -, R, o, s, a, ▁Luna, ▁was, ▁built...   \n","\n","                                                 y_true  \n","0     [[▁Alan, ▁Fre, w, ▁plays, ▁with, ▁Glass, ▁Tige...  \n","1     [[▁From, ▁the, ▁Derby, shire, ▁Da, les, ▁regio...  \n","2     [[▁New, ▁Zealand, ', s, ▁Ard, more, ▁Airport, ...  \n","3     [[▁Aaron, ▁Bo, oga, ard, ▁was, ▁born, ▁in, ▁Ca...  \n","4     [[▁The, ▁city, ▁of, ▁App, leton, ▁is, ▁served,...  \n","...                                                 ...  \n","1662  [[▁The, ▁Ant, are, s, ▁rocket, ▁is, ▁manufactu...  \n","1663  [[▁A, CM, ▁Transaction, s, ▁on, ▁Information, ...  \n","1664  [[▁An, gol, a, ▁International, ▁airport, ▁is, ...  \n","1665  [[▁Ace, ▁Wild, er, ▁is, ▁an, ▁ex, ponent, ▁of,...  \n","1666  [[▁The, ▁A, -, R, o, s, a, ▁Luna, ▁was, ▁built...  \n","\n","[1667 rows x 5 columns]"]},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"source":["# Saving Predictions\n","df = pd.DataFrame({'inps':inps,'y_pred_text':y_pred_text,'y_true_text':y_true_text,'y_pred':y_pred,'y_true':y_true})\n","df"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2021-10-26T16:18:59.230938Z","iopub.status.busy":"2021-10-26T16:18:59.230680Z","iopub.status.idle":"2021-10-26T16:18:59.367130Z","shell.execute_reply":"2021-10-26T16:18:59.366395Z","shell.execute_reply.started":"2021-10-26T16:18:59.230907Z"},"trusted":true},"outputs":[],"source":["df.to_csv('/kaggle/working/results.csv',index=False)"]},{"cell_type":"markdown","metadata":{},"source":["<a href=\"./kaggle/working/finetuned-t5-30-model/pytorch_model.bin\"> Download File </a>"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2021-10-26T16:15:47.700732Z","iopub.status.busy":"2021-10-26T16:15:47.700474Z","iopub.status.idle":"2021-10-26T16:15:51.702062Z","shell.execute_reply":"2021-10-26T16:15:51.701342Z","shell.execute_reply.started":"2021-10-26T16:15:47.700702Z"},"trusted":true},"outputs":[{"data":{"text/plain":["0.5892375707626343"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["#Calculating Bleu Score\n","from torchtext.data.metrics import bleu_score\n","bleu_score([i[0] for i in y_pred], y_true)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.10"}},"nbformat":4,"nbformat_minor":4}
