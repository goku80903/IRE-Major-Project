# -*- coding: utf-8 -*-
"""IRE_ProjectMT5.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1m40R6vxjqODJGZRRbwjIw9voIJ4hQdmx
"""


import torch
import numpy as np 
from transformers import T5Tokenizer, MT5ForConditionalGeneration
from sklearn.model_selection import train_test_split
from tqdm.notebook import tqdm
import matplotlib.pyplot as plt
import pandas as pd

import torch.nn as nn
import torch.optim as optim
from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler, Dataset

device = torch.device("cuda")

# ! git clone https://github.com/goku80903/IRE-Major-Project.git

df_train = pd.read_csv('./webNLG_Hindi_Final.csv')
df_eval = pd.read_csv('./webNLG2020_dev_hindi.csv')

tokenizer = T5Tokenizer.from_pretrained('google/mt5-small')
tokenizer.add_tokens(['<S>', '<R>','<O>'])
model = MT5ForConditionalGeneration.from_pretrained('./best_modelClipped')
model.resize_token_embeddings(len(tokenizer))
model = model.to(device)

def process(sent):
  words = sent.split('|')
  final_text = ""
  mapper = {0: ' <S> ', 1: ' <R> ', 2: ' <O> '}
  start = 0
  for i, word in enumerate(words):
    splitter = word.split('&&')
    if len(splitter)==2:
      final_text+=' <O> '+splitter[0].strip() + ' <S> '+splitter[1].strip()
      start = (start+2)%3
    else:
      final_text+=mapper[start]+splitter[0].strip()
      start = (start+1)%3
  return final_text

class DS(Dataset):
    def __init__(self, df):
        self.df = df.reset_index(drop=True)
    def __len__(self):
            return self.df.shape[0]
    def __getitem__(self, idx):
            row = self.df.iloc[idx]
            input_text = process(row['input_text'])
            return input_text,row['target_text_hindi']

# df_train, df_eval = train_test_split(df_train, test_size=0.33, random_state=42)
train_DS = DS(df_train)
train_sampler = RandomSampler(train_DS)
train_loader = DataLoader(train_DS, batch_size=1, sampler = train_sampler)
eval_DS = DS(df_eval)
eval_sampler = SequentialSampler(eval_DS)
eval_loader = DataLoader(eval_DS, batch_size=1, sampler = eval_sampler)

from transformers import AdamW
optimizer = AdamW(model.parameters(), lr = 5e-5)
# optimizer = torch.optim.Adam(model.parameters(), lr = 1e-2)

def evaluate(model, dataloader):
  model.eval()
  model.zero_grad()
  losses = []
  for step, batch in tqdm(enumerate(dataloader), total=len(dataloader)): 
    inputs, labels = batch 
    encoding = tokenizer(list(inputs),
                        padding='longest',
                        max_length=100,
                        truncation=True,
                        return_tensors="pt")
    input_ids, attention_mask = encoding.input_ids, encoding.attention_mask
    input_ids = input_ids.to(device) 
    attention_mask = attention_mask.to(device)
    target_labels = []
    with tokenizer.as_target_tokenizer():
      labels = tokenizer(labels,padding='max_length',max_length = 100, truncation=True, return_tensors="pt")['input_ids']
    labels = labels.to(device)
    model.zero_grad()
    output = model(input_ids, attention_mask = attention_mask, labels = labels)
    loss = output.loss
    losses.append(loss.tolist())
  return np.array(losses).mean()

def train(model, train_dataloader, dev_dataloader, epochs):
  model.train()
  best_loss = 10
  for epoch in range(epochs):
    losses = []
    for step, batch in tqdm(enumerate(train_dataloader), total=len(train_dataloader)): 
      inputs, labels = batch 
      encoding = tokenizer(list(inputs),
                          padding='longest',
                          max_length=100,
                          truncation=True,
                          return_tensors="pt")
      input_ids, attention_mask = encoding.input_ids, encoding.attention_mask
      input_ids = input_ids.to(device) 
      attention_mask = attention_mask.to(device)
      target_labels = []
      with tokenizer.as_target_tokenizer():
        labels = tokenizer(labels,padding='max_length',max_length = 100, truncation=True, return_tensors="pt")['input_ids']
      labels = labels.to(device)
      model.zero_grad()
      output = model(input_ids, attention_mask = attention_mask, labels = labels)
      loss = output.loss
      loss.backward()
      nn.utils.clip_grad_norm_(model.parameters(), max_norm=2.0, norm_type=2)
      optimizer.step()
      losses.append(loss.tolist())
    with torch.no_grad():
      val_loss = evaluate(model, dev_dataloader)
    print("Epoch: ", epoch, " Loss: ", np.array(losses).mean())
    print("Epoch: ", epoch, " Validation Loss: ", val_loss)
    if val_loss <= best_loss: 
      model.save_pretrained('./best_modelClipped/')
      best_loss = val_loss
      print('saved!')

torch.cuda.empty_cache()
#train(model, train_loader, eval_loader, 10)

def get_text(inp):
    with torch.no_grad():
      otp_texts=[]
      test_input_ids = tokenizer(inp,padding='longest',
                    max_length=100,
                    truncation=True,
                    return_tensors="pt")
      test_input_ids = test_input_ids.to(device)
      test_outputs = model.generate(**test_input_ids)
      print(test_outputs)
      test_outputs = test_outputs.to(torch.device('cpu'))
      otp_texts.append(tokenizer.decode(test_outputs[0], skip_special_tokens=True))
      return otp_texts

def predict(loader):
    i_s,t_s,p_s = [],[],[]
    for batch in loader:
        i,t = batch
        i_s.extend(i)
        t_s.extend(t)
        p_s.extend(get_text(list(i)))
    print(len(i_s), len(t_s), len(p_s))
    return pd.DataFrame({'input':i_s,'target':t_s,'prediction':p_s})

from torchtext.data.metrics import bleu_score
def print_score(d):
    y_true,y_pred = [],[]
    for text in tqdm(d['input'].unique()):
        y_true.append(d[d['input']==text]['target'].unique().tolist())
        y_pred.append(d[d['input']==text]['prediction'].unique().tolist())
    s = bleu_score([i[0].split() for i in y_pred], [[j.split() for j in i] for i in y_true])
    return s

d = predict(train_loader)
d.to_csv('predictions_on_train.csv',index=False)
print('Bleu Score on train set ',print_score(d))

d = predict(eval_loader)
d.to_csv('predictions_on_validation.csv',index=False)
print('Bleu Score on validation set ',print_score(d))
