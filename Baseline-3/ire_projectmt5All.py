# -*- coding: utf-8 -*-
"""IRE_ProjectMT5.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1m40R6vxjqODJGZRRbwjIw9voIJ4hQdmx
"""


import torch
import numpy as np 
from transformers import T5Tokenizer, MT5ForConditionalGeneration
from sklearn.model_selection import train_test_split
from tqdm.notebook import tqdm
import matplotlib.pyplot as plt
import pandas as pd

import torch.nn as nn
import torch.optim as optim
from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler, Dataset

device = torch.device("cuda")

df_train = pd.read_csv('./bart/input/df_test.csv')
df_eval = pd.read_csv('./bart/input/df_validation.csv')
df_test = pd.read_csv('./bart/input/df_test.csv')

tokenizer = T5Tokenizer.from_pretrained('google/mt5-small')
tokenizer.add_tokens(['<S>', '<R>','<O>'])
model = MT5ForConditionalGeneration.from_pretrained('./best_modelbaseline++/')
#model = MT5ForConditionalGeneration.from_pretrained('google/mt5-small')
model.resize_token_embeddings(len(tokenizer))
model = model.to(device)

def get_preprend_token(x): return 'russian' if 'Russian:' in x else 'hindi' if 'Hindi:' in x else 'english'
class DS(Dataset):
    def __init__(self, df):
        self.df = df.reset_index(drop=True)
        self.df['lang'] = self.df['input'].map(get_preprend_token)
        self.df = self.df[self.df.lang=='hindi']
    def __len__(self):
            return self.df.shape[0]
    def __getitem__(self, idx):
            row = self.df.iloc[idx]
            return row['input'],row['target'],row['lang']

# df_train, df_eval = train_test_split(df_train, test_size=0.33, random_state=42)
train_DS = DS(df_train)
train_sampler = RandomSampler(train_DS)
train_loader = DataLoader(train_DS, batch_size=1, sampler = train_sampler)
eval_DS = DS(df_eval)
eval_sampler = SequentialSampler(eval_DS)
eval_loader = DataLoader(eval_DS, batch_size=1, sampler = eval_sampler)
test_DS = DS(df_test)
test_sampler = SequentialSampler(test_DS)
test_loader = DataLoader(test_DS, batch_size=1, sampler = test_sampler)

from transformers import AdamW
optimizer = AdamW(model.parameters(), lr = 5e-5)
# optimizer = torch.optim.Adam(model.parameters(), lr = 1e-2)

def evaluate(model, dataloader):
  model.eval()
  model.zero_grad()
  losses = []
  for step, batch in tqdm(enumerate(dataloader), total=len(dataloader)): 
    inputs, labels, lang = batch 
    encoding = tokenizer(list(inputs),
                        padding='longest',
                        max_length=100,
                        truncation=True,
                        return_tensors="pt")
    input_ids, attention_mask = encoding.input_ids, encoding.attention_mask
    input_ids = input_ids.to(device) 
    attention_mask = attention_mask.to(device)
    target_labels = []
    with tokenizer.as_target_tokenizer():
      labels = tokenizer(labels,padding='max_length',max_length = 100, truncation=True, return_tensors="pt")['input_ids']
    labels = labels.to(device)
    model.zero_grad()
    output = model(input_ids, attention_mask = attention_mask, labels = labels,)
    loss = output.loss
    losses.append(loss.tolist())
  return np.array(losses).mean()

def train(model, train_dataloader, dev_dataloader, epochs):
  model.train()
  best_loss = 10
  for epoch in range(epochs):
    losses = []
    for step, batch in tqdm(enumerate(train_dataloader), total=len(train_dataloader)): 
      inputs, labels, lang = batch 
      encoding = tokenizer(list(inputs),
                          padding='longest',
                          max_length=100,
                          truncation=True,
                          return_tensors="pt")
      input_ids, attention_mask = encoding.input_ids, encoding.attention_mask
      input_ids = input_ids.to(device) 
      attention_mask = attention_mask.to(device)
      target_labels = []
      with tokenizer.as_target_tokenizer():
        labels = tokenizer(labels,padding='max_length',max_length = 100, truncation=True, return_tensors="pt")['input_ids']
      labels = labels.to(device)
      model.zero_grad()
      output = model(input_ids, attention_mask = attention_mask, labels = labels)
      loss = output.loss
      loss.backward()
      nn.utils.clip_grad_norm_(model.parameters(), max_norm=2.0, norm_type=2)
      optimizer.step()
      losses.append(loss.tolist())
    with torch.no_grad():
      val_loss = evaluate(model, dev_dataloader)
    print("Epoch: ", epoch, " Loss: ", np.array(losses).mean())
    print("Epoch: ", epoch, " Validation Loss: ", val_loss)
    if val_loss <= best_loss: 
      model.save_pretrained('./best_modelbaseline++/')
      best_loss = val_loss  
      print('saved!')

torch.cuda.empty_cache()
#train(model, train_loader, eval_loader, 10)

def get_text(inp,lang):
    with torch.no_grad():
      otp_texts=[]
      test_input_ids = tokenizer(inp,padding='longest',
                    max_length=100,
                    truncation=True,
                    return_tensors="pt")
      test_input_ids = test_input_ids.to(device)
      test_outputs = model.generate(**test_input_ids)
      test_outputs = test_outputs.to(torch.device('cpu'))
      otp_texts.append(tokenizer.decode(test_outputs[0], skip_special_tokens=True))
      return otp_texts

def predict(loader):
    i_s,t_s,l_s,p_s = [],[],[],[]
    for batch in loader:
        i,t,l = batch
        i_s.extend(i)
        t_s.extend(t)
        l_s.extend(l)
        p_s.extend(get_text(list(i),l))
    return pd.DataFrame({'input':i_s,'target':t_s,'language':l_s,'prediction':p_s})

from torchtext.data.metrics import bleu_score
def print_score(d):
    y_true,y_pred = [],[]
    for text in tqdm(d['input'].unique()):
        y_true.append(d[d['input']==text]['target'].unique().tolist())
        y_pred.append(d[d['input']==text]['prediction'].unique().tolist())
    s = bleu_score([i[0].split() for i in y_pred], [[j.split() for j in i] for i in y_true])
    return s

d = predict(train_loader)
d.to_csv('predictions_on_train.csv',index=False)
print('Bleu Score on train set ',print_score(d))

d = predict(eval_loader)
d.to_csv('predictions_on_validation.csv',index=False)
print('Bleu Score on validation set ',print_score(d))

d = predict(test_loader)
d.to_csv('predictions_on_test_set.csv',index=False)
print('Bleu score on test set', print_score(d))
